=pod

=for advent_year 2010

=for advent_day 21

=for advent_title Robot Santa asks, "Is your code nice enough?"

=for advent_author Jerrad Pierce

Even when your hardware's rated at 50 D<megachecks> per second, it is
sometimes necessary to streamline your code.N<evilroot> Alas, due to
the vagaries of processor scheduling, disk access, <em>D<et cetera></em>,
benchmarking is an inherently futile activity, fraught with uncertainty
not dissimilar to that experienced in quantum mechanics &hellip;to
paraphrase the fine manual of today's feature module. But things are a
little better if you apply statistics. Therefore M<Benchmark::Timer>
uses Student's t-Test to determine how many times it should execute
your code so that it can return an accurate run-time, within limits
you define, rather than you having to choose and wait for some
arbitrarily large number of times to loop.

=begin pre

% perl mod21.pl
69 trials of factorial (532.050ms total), 7.711ms/trial
Error: +/- 0.00038 with 95 confidence

=end pre

Other features of M<Benchmark::Timer> include the abilities to time your code
inline without having to roll it into subroutines, and to benchmark arbitrary 
chunks of code including subsets of the statements included in other "tags."
The module also allows you to control for slow and expensive hits incurred
by initial runs, such as loading files into the system's buffers, by discarding
the data from initial runs with the I<skip> option.

Some misfeatures of M<Benchmark::Timer> are the need to explicitly specify a
I<minimum> greater than one in order to ensure adequate statistics are gathered.
In addition, it is sometimes necessary e.g; when only one test is run; to
C<sleep> or perform some other timely operations before requesting a report
from M<Benchmark::Timer> so that internal checks the method relies upon are
cleared.

=sourcedcode mod21.pl

=begin footnote evilroot

Just be sure to stay on the nice list and avoid the temptation of premature optimization.

=end footnote

=cut